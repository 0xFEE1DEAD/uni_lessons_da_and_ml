{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586a36ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "import polars as pls\n",
    "import pytorch_lightning as pl\n",
    "import tokenizers\n",
    "import torch\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from sacrebleu import corpus_bleu, corpus_chrf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320e2e80",
   "metadata": {},
   "source": [
    "# Загрузите обучающий и тестовый датасеты."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534becc9",
   "metadata": {},
   "source": [
    "## Загрузка датасета и его анализ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e2710cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pls.read_csv(\n",
    "    \"https://github.com/0xFEE1DEAD/tatoeba_rus_to_eng/raw/refs/heads/main/tatoeba_rus_to_eng.tsv\",\n",
    "    separator=\"\\t\",\n",
    "    has_header=False,\n",
    "    new_columns=[\"ru_id\", \"ru\", \"eng_id\", \"eng\"],\n",
    "    encoding=\"utf8\",\n",
    "    quote_char=None,\n",
    "    ignore_errors=True,\n",
    "    truncate_ragged_lines=True,\n",
    "    n_rows=15000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49a6bd59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>ru_id</th><th>ru</th><th>eng_id</th><th>eng</th></tr><tr><td>i64</td><td>str</td><td>i64</td><td>str</td></tr></thead><tbody><tr><td>243</td><td>&quot;Один раз в жизни я делаю хорош…</td><td>3257</td><td>&quot;For once in my life I&#x27;m doing …</td></tr><tr><td>5409</td><td>&quot;Давайте что-нибудь попробуем!&quot;</td><td>1276</td><td>&quot;Let&#x27;s try something.&quot;</td></tr><tr><td>5410</td><td>&quot;Мне пора идти спать.&quot;</td><td>1277</td><td>&quot;I have to go to sleep.&quot;</td></tr><tr><td>5411</td><td>&quot;Что ты делаешь?&quot;</td><td>16492</td><td>&quot;What are you doing?&quot;</td></tr><tr><td>5411</td><td>&quot;Что ты делаешь?&quot;</td><td>511884</td><td>&quot;What do you make?&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 4)\n",
       "┌───────┬─────────────────────────────────┬────────┬─────────────────────────────────┐\n",
       "│ ru_id ┆ ru                              ┆ eng_id ┆ eng                             │\n",
       "│ ---   ┆ ---                             ┆ ---    ┆ ---                             │\n",
       "│ i64   ┆ str                             ┆ i64    ┆ str                             │\n",
       "╞═══════╪═════════════════════════════════╪════════╪═════════════════════════════════╡\n",
       "│ 243   ┆ Один раз в жизни я делаю хорош… ┆ 3257   ┆ For once in my life I'm doing … │\n",
       "│ 5409  ┆ Давайте что-нибудь попробуем!   ┆ 1276   ┆ Let's try something.            │\n",
       "│ 5410  ┆ Мне пора идти спать.            ┆ 1277   ┆ I have to go to sleep.          │\n",
       "│ 5411  ┆ Что ты делаешь?                 ┆ 16492  ┆ What are you doing?             │\n",
       "│ 5411  ┆ Что ты делаешь?                 ┆ 511884 ┆ What do you make?               │\n",
       "└───────┴─────────────────────────────────┴────────┴─────────────────────────────────┘"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07411f49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15000, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f53199c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>ru_id</th><th>ru</th><th>eng_id</th><th>eng</th></tr><tr><td>u32</td><td>u32</td><td>u32</td><td>u32</td></tr></thead><tbody><tr><td>0</td><td>0</td><td>0</td><td>0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1, 4)\n",
       "┌───────┬─────┬────────┬─────┐\n",
       "│ ru_id ┆ ru  ┆ eng_id ┆ eng │\n",
       "│ ---   ┆ --- ┆ ---    ┆ --- │\n",
       "│ u32   ┆ u32 ┆ u32    ┆ u32 │\n",
       "╞═══════╪═════╪════════╪═════╡\n",
       "│ 0     ┆ 0   ┆ 0      ┆ 0   │\n",
       "└───────┴─────┴────────┴─────┘"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.null_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb6ab41",
   "metadata": {},
   "source": [
    "## Подготовка токенайзера"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1faeae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tokenizers.SentencePieceBPETokenizer()\n",
    "tokenizer.normalizer = tokenizers.normalizers.Sequence(\n",
    "    [\n",
    "        tokenizers.normalizers.NFD(),\n",
    "        tokenizers.normalizers.Lowercase(),\n",
    "        tokenizers.normalizers.StripAccents(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "tokenizer.train_from_iterator(\n",
    "    df[\"ru\"].to_list() + df[\"eng\"].to_list(),\n",
    "    special_tokens=[\"<s>\", \"</s>\", \"<unk>\", \"<pad>\"],\n",
    ")\n",
    "tokenizer.save(\"seq2seq_tokenizer.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad56b1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tokenizers.Tokenizer.from_file(\"seq2seq_tokenizer.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "061c5cf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6112, 2745]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"Hello, Привет\").ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6897ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tokenizer:\n",
    "    def __init__(self, tokenizer: tokenizers.Tokenizer, max_len: int):\n",
    "        self.tkz = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def encode(self, seq: str) -> list[int]:\n",
    "        encoded = self.tkz.encode(seq)\n",
    "        encoded = encoded.ids[: self.max_len - 2]\n",
    "\n",
    "        if len(encoded) < (self.max_len - 2):\n",
    "            encoded += [self.tkz.token_to_id(\"<pad>\")] * (self.max_len - len(encoded) - 2)\n",
    "\n",
    "        return [self.tkz.token_to_id(\"<s>\")] + encoded + [self.tkz.token_to_id(\"</s>\")]\n",
    "\n",
    "    def decode(self, seq: list[int]) -> str:\n",
    "        return self.tkz.decode(seq, skip_special_tokens=True)\n",
    "\n",
    "    def get_pad_token_id(self) -> int:\n",
    "        return self.tkz.token_to_id(\"<pad>\")\n",
    "\n",
    "    def get_bos_token_id(self) -> int:\n",
    "        return self.tkz.token_to_id(\"<s>\")\n",
    "\n",
    "    def get_eos_token_id(self) -> int:\n",
    "        return self.tkz.token_to_id(\"</s>\")\n",
    "\n",
    "    def get_vocab_size(self) -> int:\n",
    "        return self.tkz.get_vocab_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "660e57bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 6112, 2745, 3, 1]\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "test_my_tokenizer = Tokenizer(tokenizer, 5)\n",
    "print(test_my_tokenizer.encode(\"Hello, Привет\"))\n",
    "print(len(test_my_tokenizer.encode(\"Hello, Привет\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c5f5baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 6112, 2745, 2745, 1]\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "print(test_my_tokenizer.encode(\"Hello, Привет Привет Привет Привет\"))\n",
    "print(len(test_my_tokenizer.encode(\"Hello, Привет Привет Привет Привет Привет\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18a50372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello, привет привет\n"
     ]
    }
   ],
   "source": [
    "print(test_my_tokenizer.decode(test_my_tokenizer.encode(\"Hello, Привет Привет Привет Привет Привет\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "90d02aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_tokenizer = Tokenizer(tokenizer, 128)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b783707e",
   "metadata": {},
   "source": [
    "## Определение класса датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ec171df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        tokenizer: Tokenizer,\n",
    "        ru_texts: list[str],\n",
    "        en_texts: list[str],\n",
    "    ):\n",
    "        self.ru_texts = ru_texts\n",
    "        self.en_texts = en_texts\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.ru_texts)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        ru_text = self.ru_texts[idx]\n",
    "        en_text = self.en_texts[idx]\n",
    "\n",
    "        ru_tokenized = self.tokenizer.encode(ru_text)\n",
    "        en_tokenized = self.tokenizer.encode(en_text)\n",
    "\n",
    "        return torch.tensor(ru_tokenized, dtype=torch.long), torch.tensor(en_tokenized, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f7017d",
   "metadata": {},
   "source": [
    "## Определение датамодуля"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e7970ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataModule(pl.LightningDataModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        df: pls.DataFrame,\n",
    "        tokenizer: Tokenizer,\n",
    "        batch_size: int = 32,\n",
    "        num_workers: int = 4,\n",
    "        val_test_size: float = 0.2,\n",
    "        test_size: float = 0.5,\n",
    "        random_state: int = 42,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.df = df\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        self.val_test_size = val_test_size\n",
    "        self.test_size = test_size\n",
    "        self.random_state = random_state\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "        # Отключаем параллелизм tokenizers — предотвращает дедлоки\n",
    "        os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "    def setup(self, stage: str | None = None) -> None:\n",
    "        # Выбираем колонки\n",
    "        ru_texts = self.df[\"ru\"].cast(pls.Utf8).to_list()\n",
    "        en_texts = self.df[\"eng\"].cast(pls.Utf8).to_list()\n",
    "\n",
    "        train_ru, temp_ru, train_en, temp_en = train_test_split(\n",
    "            ru_texts,\n",
    "            en_texts,\n",
    "            test_size=self.val_test_size,\n",
    "            random_state=self.random_state,\n",
    "            shuffle=True,\n",
    "        )\n",
    "        # Разделение temp на val и test\n",
    "        val_ru, test_ru, val_en, test_en = train_test_split(\n",
    "            temp_ru,\n",
    "            temp_en,\n",
    "            test_size=self.test_size,\n",
    "            random_state=self.random_state,\n",
    "            shuffle=True,\n",
    "        )\n",
    "\n",
    "        self.train_dataset = TextDataset(\n",
    "            ru_texts=train_ru,\n",
    "            en_texts=train_en,\n",
    "            tokenizer=self.tokenizer,\n",
    "        )\n",
    "        self.val_dataset = TextDataset(\n",
    "            ru_texts=val_ru,\n",
    "            en_texts=val_en,\n",
    "            tokenizer=self.tokenizer,\n",
    "        )\n",
    "        self.test_dataset = TextDataset(\n",
    "            ru_texts=test_ru,\n",
    "            en_texts=test_en,\n",
    "            tokenizer=self.tokenizer,\n",
    "        )\n",
    "\n",
    "    def train_dataloader(self) -> DataLoader:\n",
    "        return DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=self.num_workers,\n",
    "            pin_memory=True,\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self) -> DataLoader:\n",
    "        return DataLoader(\n",
    "            self.val_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=self.num_workers,\n",
    "            pin_memory=True,\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self) -> DataLoader:\n",
    "        return DataLoader(\n",
    "            self.test_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=self.num_workers,\n",
    "            pin_memory=True,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2545da94",
   "metadata": {},
   "source": [
    "## Проверка что все работает корректно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e92b68fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = TextDataModule(\n",
    "    tokenizer=complete_tokenizer,\n",
    "    df=df,\n",
    "    batch_size=24,\n",
    "    num_workers=0,  # На Windows >0 приводит к deadlock\n",
    ")\n",
    "dm.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d239f0a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ from seq: torch.Size([24, 128])\n",
      "✅ from seq: tensor([    0,   305,   116,   604,  4333,   604,   685, 19654,     3,     3,\n",
      "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "            3,     3,     3,     3,     3,     3,     3,     1])\n",
      "✅ to seq: torch.Size([24, 128])\n",
      "✅ to seq: tensor([    0,  1907,   182,   120,  5753, 14737,   164, 14929,     3,     3,\n",
      "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "            3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
      "            3,     3,     3,     3,     3,     3,     3,     1])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "batch = next(iter(dm.train_dataloader()))\n",
    "print(\"✅ from seq:\", batch[0].shape)\n",
    "print(\"✅ from seq:\", batch[0][0])\n",
    "print(\"✅ to seq:\", batch[1].shape)\n",
    "print(\"✅ to seq:\", batch[1][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b61e8f",
   "metadata": {},
   "source": [
    "# Обучите модели seq2seq и seq2seq + attention на тренинговом датасете для перевода с одного языка на другой"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8f502e",
   "metadata": {},
   "source": [
    "## Определение класса модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a672d20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderInterface(ABC):\n",
    "    @abstractmethod\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_size: int,\n",
    "        emb_dim: int,\n",
    "        hidden_size: int,\n",
    "        padding_idx: int,\n",
    "        num_layers: int = 1,\n",
    "        dropout: float = 0.0,\n",
    "    ) -> None:\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def forward(\n",
    "        self,\n",
    "        x: torch.Tensor,\n",
    "        hidden: torch.Tensor,\n",
    "        encoder_outputs: torch.Tensor,\n",
    "    ) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d7e22400",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_size: int,\n",
    "        emb_dim: int,\n",
    "        hidden_size: int,\n",
    "        padding_idx: int,\n",
    "        num_layers: int = 1,\n",
    "        dropout: float = 0.0,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_dim, padding_idx=padding_idx)\n",
    "        self.gru = nn.GRU(\n",
    "            input_size=emb_dim,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            dropout=dropout if num_layers > 1 else 0.0,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        embedded = self.dropout(self.embedding(x))\n",
    "        outputs, hidden = self.gru(embedded)\n",
    "        return outputs, hidden\n",
    "\n",
    "\n",
    "class Decoder(nn.Module, DecoderInterface):\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_size: int,\n",
    "        emb_dim: int,\n",
    "        hidden_size: int,\n",
    "        padding_idx: int,\n",
    "        num_layers: int = 1,\n",
    "        dropout: float = 0.0,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_dim, padding_idx=padding_idx)\n",
    "        self.gru = nn.GRU(\n",
    "            input_size=emb_dim,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            dropout=dropout if num_layers > 1 else 0.0,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.fc_out = nn.Linear(hidden_size, vocab_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        x: torch.Tensor,\n",
    "        hidden: torch.Tensor,\n",
    "        encoder_outputs: torch.Tensor,\n",
    "    ) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        embedded = self.dropout(self.embedding(x))\n",
    "        output, hidden = self.gru(embedded, hidden)\n",
    "        prediction = self.fc_out(output.squeeze(1))\n",
    "        return prediction, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9cdd22e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqGRU(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        tokenizer: Tokenizer,\n",
    "        emb_dim: int = 256,\n",
    "        hidden_size: int = 512,\n",
    "        num_layers: int = 4,\n",
    "        dropout: float = 0.3,\n",
    "        learning_rate: float = 1e-3,\n",
    "        max_length: int = 128,\n",
    "        decoder_class: type[DecoderInterface] = Decoder,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = Encoder(\n",
    "            vocab_size=tokenizer.get_vocab_size(),\n",
    "            emb_dim=emb_dim,\n",
    "            hidden_size=hidden_size,\n",
    "            padding_idx=tokenizer.get_pad_token_id(),\n",
    "            num_layers=num_layers,\n",
    "            dropout=dropout,\n",
    "        )\n",
    "        self.decoder = decoder_class(\n",
    "            vocab_size=tokenizer.get_vocab_size(),\n",
    "            emb_dim=emb_dim,\n",
    "            hidden_size=hidden_size,\n",
    "            padding_idx=tokenizer.get_pad_token_id(),\n",
    "            num_layers=num_layers,\n",
    "            dropout=dropout,\n",
    "        )\n",
    "\n",
    "        self.loss_fn = nn.CrossEntropyLoss(ignore_index=tokenizer.get_pad_token_id(), label_smoothing=0.1)\n",
    "\n",
    "        self.max_length = max_length\n",
    "        self.learning_rate = learning_rate\n",
    "        self.tokenizer = tokenizer\n",
    "        self.val_predictions = []\n",
    "        self.val_references = []\n",
    "\n",
    "    def translate(self, src_text: str) -> str:\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            src_ids = self.tokenizer.encode(src_text)\n",
    "\n",
    "            src_tensor = torch.tensor(src_ids, dtype=torch.long, device=self.device).unsqueeze(0)\n",
    "\n",
    "            assert (src_tensor[:, 0] == self.tokenizer.get_bos_token_id()).all(), \"src must start with BOS!\"\n",
    "            assert (src_tensor[:, -1] == self.tokenizer.get_eos_token_id()).all(), \"src must end with EOS!\"\n",
    "\n",
    "            logits = self(src_tensor)\n",
    "\n",
    "            tokens = self._prepare_logits(logits)\n",
    "\n",
    "            return self.tokenizer.decode(tokens[0].tolist())\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        src: torch.Tensor,\n",
    "        tgt: torch.Tensor | None = None,\n",
    "        teacher_forcing_ratio: float = 0.4,\n",
    "    ) -> torch.Tensor:\n",
    "        batch_size = src.size(0)\n",
    "\n",
    "        encoder_outputs, hidden = self.encoder(src)\n",
    "\n",
    "        if tgt is not None:\n",
    "            tgt_len = tgt.size(1)  # L\n",
    "            outputs = torch.zeros(batch_size, tgt_len, self.tokenizer.get_vocab_size()).to(src.device)\n",
    "\n",
    "            input_token = tgt[:, 0].unsqueeze(1)\n",
    "\n",
    "            for t in range(1, tgt_len):\n",
    "                # Декодер ожидает [B, 1]\n",
    "                output, hidden = self.decoder(input_token, hidden, encoder_outputs)  # output: [B, V]\n",
    "                outputs[:, t] = output\n",
    "\n",
    "                # Решаем, использовать ли teacher forcing\n",
    "                teacher_force = torch.rand(()).item() < teacher_forcing_ratio\n",
    "                input_token = tgt[:, t].unsqueeze(1) if teacher_force else output.argmax(1, keepdim=True)\n",
    "\n",
    "            return outputs\n",
    "\n",
    "        outputs = []\n",
    "\n",
    "        input_token = torch.full(\n",
    "            (batch_size, 1),\n",
    "            self.tokenizer.get_bos_token_id(),\n",
    "            dtype=torch.long,\n",
    "            device=src.device,\n",
    "        )\n",
    "        for _ in range(self.max_length):\n",
    "            output, hidden = self.decoder(input_token, hidden, encoder_outputs)  # [B, V]\n",
    "            outputs.append(output)\n",
    "\n",
    "            input_token = output.argmax(1, keepdim=True)  # [B, 1]\n",
    "\n",
    "        return torch.stack(outputs, dim=1)\n",
    "\n",
    "    def training_step(self, batch, batch_idx) -> float:\n",
    "        src, tgt = batch\n",
    "\n",
    "        assert (tgt[:, 0] == self.tokenizer.get_bos_token_id()).all(), \"tgt must start with BOS!\"\n",
    "        assert (tgt[:, -1] == self.tokenizer.get_eos_token_id()).all(), \"tgt must end with EOS!\"\n",
    "        assert (src[:, 0] == self.tokenizer.get_bos_token_id()).all(), \"src must start with BOS!\"\n",
    "        assert (src[:, -1] == self.tokenizer.get_eos_token_id()).all(), \"src must end with EOS!\"\n",
    "\n",
    "        logits = self(src, tgt, teacher_forcing_ratio=0.65)\n",
    "        out_to_loss = logits[:, 1:].reshape(-1, logits.size(2))\n",
    "        tgt_to_loss = tgt[:, 1:].reshape(-1)\n",
    "\n",
    "        loss = self.loss_fn(out_to_loss, tgt_to_loss)\n",
    "\n",
    "        self.log(\"train_loss\", loss, prog_bar=True, on_step=True, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx) -> float:\n",
    "        src, tgt = batch\n",
    "\n",
    "        assert (tgt[:, 0] == self.tokenizer.get_bos_token_id()).all(), \"tgt must start with BOS!\"\n",
    "        assert (tgt[:, -1] == self.tokenizer.get_eos_token_id()).all(), \"tgt must end with EOS!\"\n",
    "        assert (src[:, 0] == self.tokenizer.get_bos_token_id()).all(), \"src must start with BOS!\"\n",
    "        assert (src[:, -1] == self.tokenizer.get_eos_token_id()).all(), \"src must end with EOS!\"\n",
    "\n",
    "        logits = self(src, tgt)\n",
    "        out_to_loss = logits[:, 1:].reshape(-1, logits.size(2))\n",
    "        tgt_to_loss = tgt[:, 1:].reshape(-1)\n",
    "        loss = self.loss_fn(out_to_loss, tgt_to_loss)\n",
    "        self.log(\"val_loss\", loss, prog_bar=True, on_step=False, on_epoch=True)\n",
    "        self._collect_translations(logits, tgt)\n",
    "        return loss\n",
    "\n",
    "    def _prepare_logits(self, logits: torch.Tensor) -> torch.Tensor:\n",
    "        pred_tokens = logits.argmax(-1)\n",
    "        # очищаем мусор\n",
    "        for t in range(pred_tokens.size(0)):\n",
    "            eos_mask = pred_tokens[t] == self.tokenizer.get_eos_token_id()\n",
    "            cumsum_eos = eos_mask.cumsum(dim=0)\n",
    "            pred_tokens[t][cumsum_eos > 0] = self.tokenizer.get_pad_token_id()\n",
    "\n",
    "        return pred_tokens\n",
    "\n",
    "    def _collect_translations(self, predictions: torch.Tensor, tgt_tokens: torch.Tensor) -> None:\n",
    "        \"\"\"Собирает предсказания и референсы для метрик.\"\"\"\n",
    "        pred_tokens = self._prepare_logits(predictions)\n",
    "\n",
    "        for pred, tgt in zip(pred_tokens, tgt_tokens):\n",
    "            pred_text = self.tokenizer.decode(pred.tolist())\n",
    "            tgt_text = self.tokenizer.decode(tgt.tolist())\n",
    "\n",
    "            self.val_predictions.append(pred_text)\n",
    "            self.val_references.append(tgt_text)\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        if not self.val_predictions and not self.val_references:\n",
    "            return\n",
    "\n",
    "        bleu = corpus_bleu(self.val_predictions, [self.val_references])\n",
    "        chrf = corpus_chrf(self.val_predictions, [self.val_references])\n",
    "\n",
    "        self.log(\"val_bleu\", bleu.score, prog_bar=True)\n",
    "        self.log(\"val_chrf\", chrf.score, prog_bar=True)\n",
    "\n",
    "        self.val_predictions.clear()\n",
    "        self.val_references.clear()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.SGD(self.parameters(), lr=self.learning_rate, momentum=0.99)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a21782",
   "metadata": {},
   "source": [
    "### Проверка что все корректно работает"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5408b04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "s2sgru = Seq2SeqGRU(complete_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2d03348e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    s2sgru.training_step(batch, 0)\n",
    "    s2sgru.validation_step(batch, 0)\n",
    "    s2sgru.on_validation_epoch_end()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7bf550",
   "metadata": {},
   "source": [
    "Ошибок нет, можно переходить к обучению"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19da2a5",
   "metadata": {},
   "source": [
    "## Обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b43bfda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_leaning(\n",
    "    name: str,\n",
    "    n_layers: int,\n",
    "    embed_size: int,\n",
    "    hidden_size: int,\n",
    "    datamodule: TextDataModule,\n",
    "    tokenizer: Tokenizer,\n",
    "    decoder_class: type[DecoderInterface] = Decoder,\n",
    "):\n",
    "    \"\"\"Запустить обучение модели.\"\"\"\n",
    "    torch.manual_seed(42)\n",
    "    logger = TensorBoardLogger(\n",
    "        save_dir=\"logs\",\n",
    "        name=name,\n",
    "    )\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        dirpath=f\"checkpoints/{name}\",\n",
    "        filename=f\"best-[ls_{n_layers}-es_{embed_size}-hs_{hidden_size}]\" + \"-{epoch}-{val_loss:.6f}\",\n",
    "        save_top_k=3,\n",
    "        monitor=\"val_loss\",\n",
    "        save_last=True,\n",
    "        verbose=True,\n",
    "    )\n",
    "    early_stop_callback = EarlyStopping(monitor=\"val_loss\", patience=5, mode=\"min\", verbose=True)\n",
    "    model = Seq2SeqGRU(\n",
    "        tokenizer=tokenizer,\n",
    "        num_layers=n_layers,\n",
    "        emb_dim=embed_size,\n",
    "        hidden_size=hidden_size,\n",
    "        learning_rate=0.01,\n",
    "        decoder_class=decoder_class,\n",
    "    )\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=50,\n",
    "        accelerator=\"auto\",\n",
    "        logger=logger,\n",
    "        callbacks=[checkpoint_callback, early_stop_callback],\n",
    "        log_every_n_steps=10,\n",
    "    )\n",
    "    trainer.fit(model, datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1608e67a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\dilst\\Documents\\uni_lessons_da_and_ml\\.venv\\Lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:701: Checkpoint directory C:\\Users\\dilst\\Documents\\uni_lessons_da_and_ml\\src\\torch_learning\\checkpoints\\simple_seq2seq_gru exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type             | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | encoder | Encoder          | 43.3 M | train\n",
      "1 | decoder | Decoder          | 69.5 M | train\n",
      "2 | loss_fn | CrossEntropyLoss | 0      | train\n",
      "-----------------------------------------------------\n",
      "112 M     Trainable params\n",
      "0         Non-trainable params\n",
      "112 M     Total params\n",
      "451.158   Total estimated model params size (MB)\n",
      "10        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93babaccbe6f4b46b51ea69b071a406b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dilst\\Documents\\uni_lessons_da_and_ml\\.venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:433: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "c:\\Users\\dilst\\Documents\\uni_lessons_da_and_ml\\.venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:433: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "241440aae3a549efb886e45eedcfdb72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7f3583644864bc89da08369c65c6765",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved. New best score: 6.872\n",
      "Epoch 0, global step 500: 'val_loss' reached 6.87159 (best 6.87159), saving model to 'C:\\\\Users\\\\dilst\\\\Documents\\\\uni_lessons_da_and_ml\\\\src\\\\torch_learning\\\\checkpoints\\\\simple_seq2seq_gru\\\\best-[ls_6-es_300-hs_1024]-epoch=0-val_loss=6.871591.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1272d5dc5474294827eb6bb7c886f94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.117 >= min_delta = 0.0. New best score: 6.754\n",
      "Epoch 1, global step 1000: 'val_loss' reached 6.75428 (best 6.75428), saving model to 'C:\\\\Users\\\\dilst\\\\Documents\\\\uni_lessons_da_and_ml\\\\src\\\\torch_learning\\\\checkpoints\\\\simple_seq2seq_gru\\\\best-[ls_6-es_300-hs_1024]-epoch=1-val_loss=6.754280.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bbb663151b84ae4aa7d1b1bdba86b6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.024 >= min_delta = 0.0. New best score: 6.730\n",
      "Epoch 2, global step 1500: 'val_loss' reached 6.73008 (best 6.73008), saving model to 'C:\\\\Users\\\\dilst\\\\Documents\\\\uni_lessons_da_and_ml\\\\src\\\\torch_learning\\\\checkpoints\\\\simple_seq2seq_gru\\\\best-[ls_6-es_300-hs_1024]-epoch=2-val_loss=6.730083.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a03f9213f33431b8175d2bc18a793be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.014 >= min_delta = 0.0. New best score: 6.716\n",
      "Epoch 3, global step 2000: 'val_loss' reached 6.71601 (best 6.71601), saving model to 'C:\\\\Users\\\\dilst\\\\Documents\\\\uni_lessons_da_and_ml\\\\src\\\\torch_learning\\\\checkpoints\\\\simple_seq2seq_gru\\\\best-[ls_6-es_300-hs_1024]-epoch=3-val_loss=6.716013.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddcccba544d04da6ad2fb28a808d156d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.017 >= min_delta = 0.0. New best score: 6.699\n",
      "Epoch 4, global step 2500: 'val_loss' reached 6.69927 (best 6.69927), saving model to 'C:\\\\Users\\\\dilst\\\\Documents\\\\uni_lessons_da_and_ml\\\\src\\\\torch_learning\\\\checkpoints\\\\simple_seq2seq_gru\\\\best-[ls_6-es_300-hs_1024]-epoch=4-val_loss=6.699272.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab680883ee9c486895d5bbd1a045815d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.032 >= min_delta = 0.0. New best score: 6.668\n",
      "Epoch 5, global step 3000: 'val_loss' reached 6.66751 (best 6.66751), saving model to 'C:\\\\Users\\\\dilst\\\\Documents\\\\uni_lessons_da_and_ml\\\\src\\\\torch_learning\\\\checkpoints\\\\simple_seq2seq_gru\\\\best-[ls_6-es_300-hs_1024]-epoch=5-val_loss=6.667512.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "509cdbc717d84e419cc4979e01703c2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.011 >= min_delta = 0.0. New best score: 6.657\n",
      "Epoch 6, global step 3500: 'val_loss' reached 6.65674 (best 6.65674), saving model to 'C:\\\\Users\\\\dilst\\\\Documents\\\\uni_lessons_da_and_ml\\\\src\\\\torch_learning\\\\checkpoints\\\\simple_seq2seq_gru\\\\best-[ls_6-es_300-hs_1024]-epoch=6-val_loss=6.656736.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1acb43dca3d54d50a4fa80c4c4a87ae1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7, global step 4000: 'val_loss' reached 6.68064 (best 6.65674), saving model to 'C:\\\\Users\\\\dilst\\\\Documents\\\\uni_lessons_da_and_ml\\\\src\\\\torch_learning\\\\checkpoints\\\\simple_seq2seq_gru\\\\best-[ls_6-es_300-hs_1024]-epoch=7-val_loss=6.680641.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "175c238f0b254520a4b261eb2e6b6c51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.001 >= min_delta = 0.0. New best score: 6.656\n",
      "Epoch 8, global step 4500: 'val_loss' reached 6.65571 (best 6.65571), saving model to 'C:\\\\Users\\\\dilst\\\\Documents\\\\uni_lessons_da_and_ml\\\\src\\\\torch_learning\\\\checkpoints\\\\simple_seq2seq_gru\\\\best-[ls_6-es_300-hs_1024]-epoch=8-val_loss=6.655707.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e1598ce310f4cb9bf1f2135381f57df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.012 >= min_delta = 0.0. New best score: 6.643\n",
      "Epoch 9, global step 5000: 'val_loss' reached 6.64322 (best 6.64322), saving model to 'C:\\\\Users\\\\dilst\\\\Documents\\\\uni_lessons_da_and_ml\\\\src\\\\torch_learning\\\\checkpoints\\\\simple_seq2seq_gru\\\\best-[ls_6-es_300-hs_1024]-epoch=9-val_loss=6.643221.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adf2d316b7d24fb6b3711245360e7420",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.006 >= min_delta = 0.0. New best score: 6.637\n",
      "Epoch 10, global step 5500: 'val_loss' reached 6.63727 (best 6.63727), saving model to 'C:\\\\Users\\\\dilst\\\\Documents\\\\uni_lessons_da_and_ml\\\\src\\\\torch_learning\\\\checkpoints\\\\simple_seq2seq_gru\\\\best-[ls_6-es_300-hs_1024]-epoch=10-val_loss=6.637270.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f710cf55be7046a59a11be7a31572b55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11, global step 6000: 'val_loss' reached 6.64345 (best 6.63727), saving model to 'C:\\\\Users\\\\dilst\\\\Documents\\\\uni_lessons_da_and_ml\\\\src\\\\torch_learning\\\\checkpoints\\\\simple_seq2seq_gru\\\\best-[ls_6-es_300-hs_1024]-epoch=11-val_loss=6.643453.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b175e1c95c504e05a572ea8c9fe3d213",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.001 >= min_delta = 0.0. New best score: 6.636\n",
      "Epoch 12, global step 6500: 'val_loss' reached 6.63616 (best 6.63616), saving model to 'C:\\\\Users\\\\dilst\\\\Documents\\\\uni_lessons_da_and_ml\\\\src\\\\torch_learning\\\\checkpoints\\\\simple_seq2seq_gru\\\\best-[ls_6-es_300-hs_1024]-epoch=12-val_loss=6.636163.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef2e1a681f8f4a0f8ca1569ad9fef725",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13, global step 7000: 'val_loss' was not in top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "419a8719fb854f1ea495920744ecead1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14, global step 7500: 'val_loss' was not in top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fac555cdc5eb486380c1ec7fb6107f13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15, global step 8000: 'val_loss' was not in top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "981e3dd50a0942659e6f809178d1cbe2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.020 >= min_delta = 0.0. New best score: 6.617\n",
      "Epoch 16, global step 8500: 'val_loss' reached 6.61659 (best 6.61659), saving model to 'C:\\\\Users\\\\dilst\\\\Documents\\\\uni_lessons_da_and_ml\\\\src\\\\torch_learning\\\\checkpoints\\\\simple_seq2seq_gru\\\\best-[ls_6-es_300-hs_1024]-epoch=16-val_loss=6.616592.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfd612b7d0bd4af1a19065975e01fb67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17, global step 9000: 'val_loss' was not in top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c20c1f5eca974468807099c5c5889498",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18, global step 9500: 'val_loss' was not in top 3\n",
      "\n",
      "Detected KeyboardInterrupt, attempting graceful shutdown ...\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[31mSystemExit\u001b[39m\u001b[31m:\u001b[39m 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dilst\\Documents\\uni_lessons_da_and_ml\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3707: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "torch.set_float32_matmul_precision(\"medium\")\n",
    "start_leaning(\"simple_seq2seq_gru\", 6, 300, 1024, dm, complete_tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311b1fa5",
   "metadata": {},
   "source": [
    "С оптимайзером Adam модель не обучалась совсем, при изменениях learning rate происходил взрыв градиентов. С SGD и большим learning rate модель обучается очень медленно, поэтому процесс пришлось принудительно остановить."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "91f17a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_model = Seq2SeqGRU.load_from_checkpoint(\n",
    "    \"checkpoints/simple_seq2seq_gru/best-[ls_6-es_300-hs_1024]-epoch=16-val_loss=6.616592.ckpt\",\n",
    "    tokenizer=complete_tokenizer,\n",
    "    num_layers=6,\n",
    "    emb_dim=300,\n",
    "    hidden_size=1024,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9aa9e368",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'he is to the the to the the the the the the to the the to the the to the the the the of the the the the the the of the the the the the the the of the the the the the the the of the the the the the the the the of the the the the the the the the of the the the the the the the the the of the the the the the the the the the of the the the the the the the the the the of the the the the the the the the the the of the the the the the the the the the the the of the the the the the the the the the'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_model.translate(\"Мне пора идти спать.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d55ced",
   "metadata": {},
   "source": [
    "Модель не удается обучить чтобы оценить какие либо результаты, она выдает самые повторяющиеся слова из английского языка которые встречаются почти во всех предложениях."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ff75d1",
   "metadata": {},
   "source": [
    "## + Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5245847",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderWithAttention(nn.Module, DecoderInterface):\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_size: int,\n",
    "        emb_dim: int,\n",
    "        hidden_size: int,\n",
    "        padding_idx: int,\n",
    "        num_layers: int = 1,\n",
    "        dropout: float = 0.0,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_dim, padding_idx=padding_idx)\n",
    "        # GRU теперь принимает emb_dim + hidden_size (эмбеддинг + контекст)\n",
    "        self.gru = nn.GRU(\n",
    "            input_size=emb_dim + hidden_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            dropout=dropout if num_layers > 1 else 0.0,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.fc_out = nn.Linear(hidden_size + hidden_size + emb_dim, vocab_size)  # [dec_hid, context, emb]\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        # Bahdanau attention\n",
    "        self.attn = nn.Linear(hidden_size * 2, hidden_size)\n",
    "        self.v = nn.Parameter(torch.rand(hidden_size))\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        x: torch.Tensor,\n",
    "        hidden: torch.Tensor,\n",
    "        encoder_outputs: torch.Tensor,\n",
    "    ) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        batch_size = x.shape[0]\n",
    "        src_len = encoder_outputs.shape[1]\n",
    "\n",
    "        embedded = self.dropout(self.embedding(x))  # [batch_size, emb_dim]\n",
    "\n",
    "        # 2. Получаем последний слой скрытого состояния (для attention)\n",
    "        # hidden: [num_layers, batch_size, hidden_size] → last_layer: [batch_size, hidden_size]\n",
    "        last_hidden = hidden[-1]  # [batch_size, hidden_size]\n",
    "\n",
    "        # 3. Вычисляем attention weights\n",
    "        # Повторяем last_hidden для каждого шага энкодера\n",
    "        hidden_expanded = last_hidden.unsqueeze(1).repeat(1, src_len, 1)  # [batch_size, src_len, hidden_size]\n",
    "\n",
    "        # energy: [batch_size, src_len, hidden_size]\n",
    "        energy = torch.tanh(self.attn(torch.cat((hidden_expanded, encoder_outputs), dim=2)))\n",
    "        # v: [hidden_size] → [batch_size, 1, hidden_size]\n",
    "        v = self.v.repeat(batch_size, 1).unsqueeze(1)\n",
    "        # attention: [batch_size, src_len]\n",
    "        attention = torch.bmm(v, energy.transpose(1, 2)).squeeze(1)\n",
    "        attention_weights = attention.softmax(dim=1)  # [batch_size, src_len]\n",
    "\n",
    "        # 4. Контекстный вектор — взвешенная сумма encoder_outputs\n",
    "        context = torch.bmm(attention_weights.unsqueeze(1), encoder_outputs)  # [batch_size, 1, hidden_size]\n",
    "\n",
    "        # 5. Подготавливаем вход для GRU: [emb + context]\n",
    "        gru_input = torch.cat((embedded, context), dim=2)  # [batch_size, 1, emb_dim + hidden_size]\n",
    "\n",
    "        # 6. Пропускаем через GRU\n",
    "        output, hidden = self.gru(gru_input, hidden)  # output: [batch_size, 1, hidden_size]\n",
    "\n",
    "        # 7. Финальный прогноз\n",
    "        output = output.squeeze(1)  # [batch_size, hidden_size]\n",
    "        context = context.squeeze(1)  # [batch_size, hidden_size]\n",
    "        embedded = embedded.squeeze(1)  # [batch_size, emb_dim]\n",
    "\n",
    "        # Объединяем всё для более выразительного прогноза\n",
    "        prediction = self.fc_out(torch.cat((output, context, embedded), dim=1))  # [batch_size, vocab_size]\n",
    "\n",
    "        return prediction, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cdd61505",
   "metadata": {},
   "outputs": [],
   "source": [
    "s2sgru_attention = Seq2SeqGRU(complete_tokenizer, decoder_class=DecoderWithAttention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "21c618b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dilst\\Documents\\uni_lessons_da_and_ml\\.venv\\Lib\\site-packages\\pytorch_lightning\\core\\module.py:449: You are trying to `self.log()` but the `self.trainer` reference is not registered on the model yet. This is most likely because the model hasn't been passed to the `Trainer`\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    s2sgru_attention.training_step(batch, 0)\n",
    "    s2sgru_attention.validation_step(batch, 0)\n",
    "    s2sgru.on_validation_epoch_end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "59c4b21d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type                 | Params | Mode \n",
      "---------------------------------------------------------\n",
      "0 | encoder | Encoder              | 13.7 M | train\n",
      "1 | decoder | DecoderWithAttention | 49.0 M | train\n",
      "2 | loss_fn | CrossEntropyLoss     | 0      | train\n",
      "---------------------------------------------------------\n",
      "62.6 M    Trainable params\n",
      "0         Non-trainable params\n",
      "62.6 M    Total params\n",
      "250.508   Total estimated model params size (MB)\n",
      "11        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88a9c871119949f4a90d044a61f76017",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d2e845da4df4af8aa4135d5594f4f70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6d1d97e55a1429f8963ba7f8a185b62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved. New best score: 7.750\n",
      "Epoch 0, global step 500: 'val_loss' reached 7.74985 (best 7.74985), saving model to 'C:\\\\Users\\\\dilst\\\\Documents\\\\uni_lessons_da_and_ml\\\\src\\\\torch_learning\\\\checkpoints\\\\attention_seq2seq_gru\\\\best-[ls_4-es_300-hs_512]-epoch=0-val_loss=7.749851.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55d7df13ed6743d8902b6144e1067d87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.319 >= min_delta = 0.0. New best score: 7.430\n",
      "Epoch 1, global step 1000: 'val_loss' reached 7.43040 (best 7.43040), saving model to 'C:\\\\Users\\\\dilst\\\\Documents\\\\uni_lessons_da_and_ml\\\\src\\\\torch_learning\\\\checkpoints\\\\attention_seq2seq_gru\\\\best-[ls_4-es_300-hs_512]-epoch=1-val_loss=7.430398.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88d0709add294c238b449f3d6dc4703f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.382 >= min_delta = 0.0. New best score: 7.049\n",
      "Epoch 2, global step 1500: 'val_loss' reached 7.04859 (best 7.04859), saving model to 'C:\\\\Users\\\\dilst\\\\Documents\\\\uni_lessons_da_and_ml\\\\src\\\\torch_learning\\\\checkpoints\\\\attention_seq2seq_gru\\\\best-[ls_4-es_300-hs_512]-epoch=2-val_loss=7.048591.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d70fe97fcee446c99a521195344d635",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.138 >= min_delta = 0.0. New best score: 6.910\n",
      "Epoch 3, global step 2000: 'val_loss' reached 6.91032 (best 6.91032), saving model to 'C:\\\\Users\\\\dilst\\\\Documents\\\\uni_lessons_da_and_ml\\\\src\\\\torch_learning\\\\checkpoints\\\\attention_seq2seq_gru\\\\best-[ls_4-es_300-hs_512]-epoch=3-val_loss=6.910320.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf61641efaf6495c830ad5679c244334",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.106 >= min_delta = 0.0. New best score: 6.804\n",
      "Epoch 4, global step 2500: 'val_loss' reached 6.80441 (best 6.80441), saving model to 'C:\\\\Users\\\\dilst\\\\Documents\\\\uni_lessons_da_and_ml\\\\src\\\\torch_learning\\\\checkpoints\\\\attention_seq2seq_gru\\\\best-[ls_4-es_300-hs_512]-epoch=4-val_loss=6.804408.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7720dedf65d042eab89c2c8361eec877",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 3000: 'val_loss' reached 6.80967 (best 6.80441), saving model to 'C:\\\\Users\\\\dilst\\\\Documents\\\\uni_lessons_da_and_ml\\\\src\\\\torch_learning\\\\checkpoints\\\\attention_seq2seq_gru\\\\best-[ls_4-es_300-hs_512]-epoch=5-val_loss=6.809674.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ac75bcfc9334ca7b4f245c2318c8003",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.109 >= min_delta = 0.0. New best score: 6.695\n",
      "Epoch 6, global step 3500: 'val_loss' reached 6.69534 (best 6.69534), saving model to 'C:\\\\Users\\\\dilst\\\\Documents\\\\uni_lessons_da_and_ml\\\\src\\\\torch_learning\\\\checkpoints\\\\attention_seq2seq_gru\\\\best-[ls_4-es_300-hs_512]-epoch=6-val_loss=6.695343.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e06de57ca954eee85fda25fab3e79f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.066 >= min_delta = 0.0. New best score: 6.630\n",
      "Epoch 7, global step 4000: 'val_loss' reached 6.62961 (best 6.62961), saving model to 'C:\\\\Users\\\\dilst\\\\Documents\\\\uni_lessons_da_and_ml\\\\src\\\\torch_learning\\\\checkpoints\\\\attention_seq2seq_gru\\\\best-[ls_4-es_300-hs_512]-epoch=7-val_loss=6.629610.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ce9efed067f4508bceeaf3900930518",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8, global step 4500: 'val_loss' reached 6.64730 (best 6.62961), saving model to 'C:\\\\Users\\\\dilst\\\\Documents\\\\uni_lessons_da_and_ml\\\\src\\\\torch_learning\\\\checkpoints\\\\attention_seq2seq_gru\\\\best-[ls_4-es_300-hs_512]-epoch=8-val_loss=6.647296.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71bf30351b0841b6b37a07782e86340f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9, global step 5000: 'val_loss' reached 6.65900 (best 6.62961), saving model to 'C:\\\\Users\\\\dilst\\\\Documents\\\\uni_lessons_da_and_ml\\\\src\\\\torch_learning\\\\checkpoints\\\\attention_seq2seq_gru\\\\best-[ls_4-es_300-hs_512]-epoch=9-val_loss=6.659003.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4683bdbc944448bcb81ea2e087470250",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10, global step 5500: 'val_loss' reached 6.64994 (best 6.62961), saving model to 'C:\\\\Users\\\\dilst\\\\Documents\\\\uni_lessons_da_and_ml\\\\src\\\\torch_learning\\\\checkpoints\\\\attention_seq2seq_gru\\\\best-[ls_4-es_300-hs_512]-epoch=10-val_loss=6.649936.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "093617a482684bc28c8c479b744d1935",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.031 >= min_delta = 0.0. New best score: 6.598\n",
      "Epoch 11, global step 6000: 'val_loss' reached 6.59843 (best 6.59843), saving model to 'C:\\\\Users\\\\dilst\\\\Documents\\\\uni_lessons_da_and_ml\\\\src\\\\torch_learning\\\\checkpoints\\\\attention_seq2seq_gru\\\\best-[ls_4-es_300-hs_512]-epoch=11-val_loss=6.598429.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c0bb00d99214b45b4ad00fc7a33e0b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.015 >= min_delta = 0.0. New best score: 6.583\n",
      "Epoch 12, global step 6500: 'val_loss' reached 6.58307 (best 6.58307), saving model to 'C:\\\\Users\\\\dilst\\\\Documents\\\\uni_lessons_da_and_ml\\\\src\\\\torch_learning\\\\checkpoints\\\\attention_seq2seq_gru\\\\best-[ls_4-es_300-hs_512]-epoch=12-val_loss=6.583066.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "072aaf3634f24875953d7174cce5c3a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.003 >= min_delta = 0.0. New best score: 6.580\n",
      "Epoch 13, global step 7000: 'val_loss' reached 6.58006 (best 6.58006), saving model to 'C:\\\\Users\\\\dilst\\\\Documents\\\\uni_lessons_da_and_ml\\\\src\\\\torch_learning\\\\checkpoints\\\\attention_seq2seq_gru\\\\best-[ls_4-es_300-hs_512]-epoch=13-val_loss=6.580057.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "607f50054f4c4ae586e0512f831bf4e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Monitored metric val_loss = nan is not finite. Previous best value was 6.580. Signaling Trainer to stop.\n",
      "Epoch 14, global step 7500: 'val_loss' was not in top 3\n"
     ]
    }
   ],
   "source": [
    "torch.set_float32_matmul_precision(\"medium\")\n",
    "start_leaning(\n",
    "    \"attention_seq2seq_gru\",\n",
    "    4,\n",
    "    300,\n",
    "    512,\n",
    "    dm,\n",
    "    complete_tokenizer,\n",
    "    DecoderWithAttention,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "11a2dbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_model = Seq2SeqGRU.load_from_checkpoint(\n",
    "    \"checkpoints/attention_seq2seq_gru/best-[ls_4-es_300-hs_512]-epoch=13-val_loss=6.580057.ckpt\",\n",
    "    tokenizer=complete_tokenizer,\n",
    "    num_layers=4,\n",
    "    emb_dim=300,\n",
    "    hidden_size=512,\n",
    "    decoder_class=DecoderWithAttention,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0b42fc9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i like the to the the the rain. day. time. time. time. time. time. time. time. time. time. time. time.ed. day.'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_model.translate(\"Мне пора идти спать.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ccd4bc",
   "metadata": {},
   "source": [
    "# Для тестового датасета сделайте перевод 30 фраз с одного языка на другой обеими моделями"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cad7370c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words_from_dataloader(dm: TextDataModule) -> tuple[list[str], list[str]]:\n",
    "    dm.setup(stage=\"test\")\n",
    "    test_words_from = []\n",
    "    test_words_to = []\n",
    "\n",
    "    for i, words in enumerate(dm.test_dataloader()):\n",
    "        seq_from, seq_to = words\n",
    "        for i in range(seq_from.size(0)):\n",
    "            test_words_from.append(complete_tokenizer.decode(seq_from[i].tolist()))\n",
    "            test_words_to.append(complete_tokenizer.decode(seq_to[i].tolist()))\n",
    "            if len(test_words_from) == 30:\n",
    "                return test_words_from, test_words_to\n",
    "\n",
    "    raise RuntimeError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c7d3a020",
   "metadata": {},
   "outputs": [],
   "source": [
    "from_s, to_s = get_words_from_dataloader(dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "dff98d0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обычная модель:\n",
      "==================================================\n",
      "    Предложение: я люблю виноград, но не могу съесть так много.\n",
      "    Результат предсказания: he is to the the to the the the the the the to the the to the the to the the the the of the the the the the the of the the the the the the the of the the the the the the the of the the the the the the the the of the the the the the the the the of the the the the the the the the the of the the the the the the the the the of the the the the the the the the the the of the the the the the the the the the the of the the the the the the the the the the the of the the the the the the the the the\n",
      "    Что должно было быть: i like grapes, but i can't eat so many.\n",
      "==================================================\n",
      "    Предложение: горбатого могила исправит.\n",
      "    Результат предсказания: he is to the the to the the the the the the to the the to the the to the the the the of the the the the the the of the the the the the the the of the the the the the the the of the the the the the the the the of the the the the the the the the of the the the the the the the the the of the the the the the the the the the of the the the the the the the the the the of the the the the the the the the the the of the the the the the the the the the the the of the the the the the the the the the\n",
      "    Что должно было быть: only death cures all pain.\n",
      "==================================================\n",
      "    Предложение: почему вы не пытаетесь произвести хорошее впечатление?\n",
      "    Результат предсказания: he is to the the to the the the the the the to the the to the the to the the the the of the the the the the the of the the the the the the the of the the the the the the the of the the the the the the the the of the the the the the the the the of the the the the the the the the the of the the the the the the the the the of the the the the the the the the the the of the the the the the the the the the the of the the the the the the the the the the the of the the the the the the the the the\n",
      "    Что должно было быть: why don't you put your best foot forward?\n",
      "==================================================\n",
      "    Предложение: могу я здесь припарковаться?\n",
      "    Результат предсказания: he is to the the to the the the the the the to the the to the the to the the the the of the the the the the the of the the the the the the the of the the the the the the the of the the the the the the the the of the the the the the the the the of the the the the the the the the the of the the the the the the the the the of the the the the the the the the the the of the the the the the the the the the the of the the the the the the the the the the the of the the the the the the the the the\n",
      "    Что должно было быть: can i park my car here?\n",
      "==================================================\n",
      "    Предложение: его сын - гении.\n",
      "    Результат предсказания: he is to the the to the the the the the the to the the to the the to the the the the of the the the the the the of the the the the the the the of the the the the the the the of the the the the the the the the of the the the the the the the the of the the the the the the the the the of the the the the the the the the the of the the the the the the the the the the of the the the the the the the the the the of the the the the the the the the the the the of the the the the the the the the the\n",
      "    Что должно было быть: his son is a genius.\n",
      "==================================================\n",
      "    Предложение: жаль, что мне не нужно сбрасывать вес.\n",
      "    Результат предсказания: he is to the the to the the the the the the to the the to the the to the the the the of the the the the the the of the the the the the the the of the the the the the the the of the the the the the the the the of the the the the the the the the of the the the the the the the the the of the the the the the the the the the of the the the the the the the the the the of the the the the the the the the the the of the the the the the the the the the the the of the the the the the the the the the\n",
      "    Что должно было быть: it's too bad that i don't need to lose weight.\n",
      "==================================================\n",
      "    Предложение: он говорит на пяти языках.\n",
      "    Результат предсказания: he is to the the to the the the the the the to the the to the the to the the the the of the the the the the the of the the the the the the the of the the the the the the the of the the the the the the the the of the the the the the the the the of the the the the the the the the the of the the the the the the the the the of the the the the the the the the the the of the the the the the the the the the the of the the the the the the the the the the the of the the the the the the the the the\n",
      "    Что должно было быть: he can speak five languages.\n",
      "==================================================\n",
      "    Предложение: что обозначает этот знак?\n",
      "    Результат предсказания: he is to the the to the the the the the the to the the to the the to the the the the of the the the the the the of the the the the the the the of the the the the the the the of the the the the the the the the of the the the the the the the the of the the the the the the the the the of the the the the the the the the the of the the the the the the the the the the of the the the the the the the the the the of the the the the the the the the the the the of the the the the the the the the the\n",
      "    Что должно было быть: what does this sign mean?\n",
      "==================================================\n",
      "    Предложение: вы чувствуете какие-нибудь боли в желудке?\n",
      "    Результат предсказания: he is to the the to the the the the the the to the the to the the to the the the the of the the the the the the of the the the the the the the of the the the the the the the of the the the the the the the the of the the the the the the the the of the the the the the the the the the of the the the the the the the the the of the the the the the the the the the the of the the the the the the the the the the of the the the the the the the the the the the of the the the the the the the the the\n",
      "    Что должно было быть: do you feel any pain in your stomach?\n",
      "==================================================\n",
      "    Предложение: я — пожизненныи кочевник.\n",
      "    Результат предсказания: he is to the the to the the the the the the to the the to the the to the the the the of the the the the the the of the the the the the the the of the the the the the the the of the the the the the the the the of the the the the the the the the of the the the the the the the the the of the the the the the the the the the of the the the the the the the the the the of the the the the the the the the the the of the the the the the the the the the the the of the the the the the the the the the\n",
      "    Что должно было быть: i'm a nomad for life.\n",
      "==================================================\n",
      "    Предложение: наконец мы достигли компромисса.\n",
      "    Результат предсказания: he is to the the to the the the the the the to the the to the the to the the the the of the the the the the the of the the the the the the the of the the the the the the the of the the the the the the the the of the the the the the the the the of the the the the the the the the the of the the the the the the the the the of the the the the the the the the the the of the the the the the the the the the the of the the the the the the the the the the the of the the the the the the the the the\n",
      "    Что должно было быть: finally, we reached a compromise.\n",
      "==================================================\n",
      "    Предложение: после заката деревня вымерла.\n",
      "    Результат предсказания: he is to the the to the the the the the the to the the to the the to the the the the of the the the the the the of the the the the the the the of the the the the the the the of the the the the the the the the of the the the the the the the the of the the the the the the the the the of the the the the the the the the the of the the the the the the the the the the of the the the the the the the the the the of the the the the the the the the the the the of the the the the the the the the the\n",
      "    Что должно было быть: the village was dead after sunset.\n",
      "==================================================\n",
      "    Предложение: это интересно.\n",
      "    Результат предсказания: he is to the the to the the the the the the to the the to the the to the the the the of the the the the the the of the the the the the the the of the the the the the the the of the the the the the the the the of the the the the the the the the of the the the the the the the the the of the the the the the the the the the of the the the the the the the the the the of the the the the the the the the the the of the the the the the the the the the the the of the the the the the the the the the\n",
      "    Что должно было быть: that is intriguing.\n",
      "==================================================\n",
      "    Предложение: у ребенка нет моральных ориентиров.\n",
      "    Результат предсказания: he is to the the to the the the the the the to the the to the the to the the the the of the the the the the the of the the the the the the the of the the the the the the the of the the the the the the the the of the the the the the the the the of the the the the the the the the the of the the the the the the the the the of the the the the the the the the the the of the the the the the the the the the the of the the the the the the the the the the the of the the the the the the the the the\n",
      "    Что должно было быть: a baby has no moral compass.\n",
      "==================================================\n",
      "    Предложение: сегодня тепло, не так ли?\n",
      "    Результат предсказания: he is to the the to the the the the the the to the the to the the to the the the the of the the the the the the of the the the the the the the of the the the the the the the of the the the the the the the the of the the the the the the the the of the the the the the the the the the of the the the the the the the the the of the the the the the the the the the the of the the the the the the the the the the of the the the the the the the the the the the of the the the the the the the the the\n",
      "    Что должно было быть: it's warm today, isn't it?\n",
      "==================================================\n",
      "    Предложение: жизнь как?\n",
      "    Результат предсказания: he is to the the to the the the the the the to the the to the the to the the the the of the the the the the the of the the the the the the the of the the the the the the the of the the the the the the the the of the the the the the the the the of the the the the the the the the the of the the the the the the the the the of the the the the the the the the the the of the the the the the the the the the the of the the the the the the the the the the the of the the the the the the the the the\n",
      "    Что должно было быть: how's life?\n",
      "==================================================\n",
      "    Предложение: я иногда вижу его на улице.\n",
      "    Результат предсказания: he is to the the to the the the the the the to the the to the the to the the the the of the the the the the the of the the the the the the the of the the the the the the the of the the the the the the the the of the the the the the the the the of the the the the the the the the the of the the the the the the the the the of the the the the the the the the the the of the the the the the the the the the the of the the the the the the the the the the the of the the the the the the the the the\n",
      "    Что должно было быть: i sometimes see him on the street.\n",
      "==================================================\n",
      "    Предложение: на бедре человека висел пистолет.\n",
      "    Результат предсказания: he is to the the to the the the the the the to the the to the the to the the the the of the the the the the the of the the the the the the the of the the the the the the the of the the the the the the the the of the the the the the the the the of the the the the the the the the the of the the the the the the the the the of the the the the the the the the the the of the the the the the the the the the the of the the the the the the the the the the the of the the the the the the the the the\n",
      "    Что должно было быть: the man wore a gun on his hip.\n",
      "==================================================\n",
      "    Предложение: у него есть привычка кивать головои, когда он слушает разговор.\n",
      "    Результат предсказания: he is to the the to the the the the the the to the the to the the to the the the the of the the the the the the of the the the the the the the of the the the the the the the of the the the the the the the the of the the the the the the the the of the the the the the the the the the of the the the the the the the the the of the the the the the the the the the the of the the the the the the the the the the of the the the the the the the the the the the of the the the the the the the the the\n",
      "    Что должно было быть: he has a habit of moving his head up and down when he is listening to a conversation.\n",
      "==================================================\n",
      "    Предложение: европеицы любят пить вино.\n",
      "    Результат предсказания: he is to the the to the the the the the the to the the to the the to the the the the of the the the the the the of the the the the the the the of the the the the the the the of the the the the the the the the of the the the the the the the the of the the the the the the the the the of the the the the the the the the the of the the the the the the the the the the of the the the the the the the the the the of the the the the the the the the the the the of the the the the the the the the the\n",
      "    Что должно было быть: europeans like to drink wine.\n",
      "==================================================\n",
      "    Предложение: он дал три неверных ответа.\n",
      "    Результат предсказания: he is to the the to the the the the the the to the the to the the to the the the the of the the the the the the of the the the the the the the of the the the the the the the of the the the the the the the the of the the the the the the the the of the the the the the the the the the of the the the the the the the the the of the the the the the the the the the the of the the the the the the the the the the of the the the the the the the the the the the of the the the the the the the the the\n",
      "    Что должно было быть: he gave three wrong answers.\n",
      "==================================================\n",
      "    Предложение: ему не позволили поступить в колледж.\n",
      "    Результат предсказания: he is to the the to the the the the the the to the the to the the to the the the the of the the the the the the of the the the the the the the of the the the the the the the of the the the the the the the the of the the the the the the the the of the the the the the the the the the of the the the the the the the the the of the the the the the the the the the the of the the the the the the the the the the of the the the the the the the the the the the of the the the the the the the the the\n",
      "    Что должно было быть: he was not allowed to enroll in the college.\n",
      "==================================================\n",
      "    Предложение: я не хочу менять свои взгляды, даже если они несколько экстремальны.\n",
      "    Результат предсказания: he is to the the to the the the the the the to the the to the the to the the the the of the the the the the the of the the the the the the the of the the the the the the the of the the the the the the the the of the the the the the the the the of the the the the the the the the the of the the the the the the the the the of the the the the the the the the the the of the the the the the the the the the the of the the the the the the the the the the the of the the the the the the the the the\n",
      "    Что должно было быть: i don't want to lose my ideas, even though some of them are a bit extreme.\n",
      "==================================================\n",
      "    Предложение: вы могли бы забрать меня с вокзала?\n",
      "    Результат предсказания: he is to the the to the the the the the the to the the to the the to the the the the of the the the the the the of the the the the the the the of the the the the the the the of the the the the the the the the of the the the the the the the the of the the the the the the the the the of the the the the the the the the the of the the the the the the the the the the of the the the the the the the the the the of the the the the the the the the the the the of the the the the the the the the the\n",
      "    Что должно было быть: can you pick me up at the station?\n",
      "==================================================\n",
      "    Предложение: молодые люди охотно ездят за границу.\n",
      "    Результат предсказания: he is to the the to the the the the the the to the the to the the to the the the the of the the the the the the of the the the the the the the of the the the the the the the of the the the the the the the the of the the the the the the the the of the the the the the the the the the of the the the the the the the the the of the the the the the the the the the the of the the the the the the the the the the of the the the the the the the the the the the of the the the the the the the the the\n",
      "    Что должно было быть: young people are eager to go abroad.\n",
      "==================================================\n",
      "    Предложение: я снимаю комнату в доме.\n",
      "    Результат предсказания: he is to the the to the the the the the the to the the to the the to the the the the of the the the the the the of the the the the the the the of the the the the the the the of the the the the the the the the of the the the the the the the the of the the the the the the the the the of the the the the the the the the the of the the the the the the the the the the of the the the the the the the the the the of the the the the the the the the the the the of the the the the the the the the the\n",
      "    Что должно было быть: i live in a rooming house.\n",
      "==================================================\n",
      "    Предложение: я очень счастлив.\n",
      "    Результат предсказания: he is to the the to the the the the the the to the the to the the to the the the the of the the the the the the of the the the the the the the of the the the the the the the of the the the the the the the the of the the the the the the the the of the the the the the the the the the of the the the the the the the the the of the the the the the the the the the the of the the the the the the the the the the of the the the the the the the the the the the of the the the the the the the the the\n",
      "    Что должно было быть: i'm very happy.\n",
      "==================================================\n",
      "    Предложение: я должен быть верен самому себе.\n",
      "    Результат предсказания: he is to the the to the the the the the the to the the to the the to the the the the of the the the the the the of the the the the the the the of the the the the the the the of the the the the the the the the of the the the the the the the the of the the the the the the the the the of the the the the the the the the the of the the the the the the the the the the of the the the the the the the the the the of the the the the the the the the the the the of the the the the the the the the the\n",
      "    Что должно было быть: i must be true to myself.\n",
      "==================================================\n",
      "    Предложение: она пишет сеичас письмо.\n",
      "    Результат предсказания: he is to the the to the the the the the the to the the to the the to the the the the of the the the the the the of the the the the the the the of the the the the the the the of the the the the the the the the of the the the the the the the the of the the the the the the the the the of the the the the the the the the the of the the the the the the the the the the of the the the the the the the the the the of the the the the the the the the the the the of the the the the the the the the the\n",
      "    Что должно было быть: she is writing a letter now.\n",
      "==================================================\n",
      "    Предложение: многие поддерживали меня в моих стремлениях.\n",
      "    Результат предсказания: he is to the the to the the the the the the to the the to the the to the the the the of the the the the the the of the the the the the the the of the the the the the the the of the the the the the the the the of the the the the the the the the of the the the the the the the the the of the the the the the the the the the of the the the the the the the the the the of the the the the the the the the the the of the the the the the the the the the the the of the the the the the the the the the\n",
      "    Что должно было быть: many people encouraged me to fulfill my ambitions.\n"
     ]
    }
   ],
   "source": [
    "print(\"Обычная модель:\")\n",
    "for fw, tw in zip(from_s, to_s):\n",
    "    result = simple_model.translate(fw)\n",
    "    print(\"=\" * 50)\n",
    "    print(\" \" * 4 + f\"Предложение: {fw}\")\n",
    "    print(\" \" * 4 + f\"Результат предсказания: {result}\")\n",
    "    print(\" \" * 4 + f\"Что должно было быть: {tw}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ab06464a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель с вниманием:\n",
      "==================================================\n",
      "    Предложение: я люблю виноград, но не могу съесть так много.\n",
      "    Результат предсказания: i don't know the to be but i the the of the of the of the of the of the the the the the the the the the the the the the the the the the the the the the the the the the the\n",
      "    Что должно было быть: i like grapes, but i can't eat so many.\n",
      "==================================================\n",
      "    Предложение: горбатого могила исправит.\n",
      "    Результат предсказания: the is is the to the rain. day.e.al.s.\n",
      "    Что должно было быть: only death cures all pain.\n",
      "==================================================\n",
      "    Предложение: почему вы не пытаетесь произвести хорошее впечатление?\n",
      "    Результат предсказания: the girl was very hard to the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the\n",
      "    Что должно было быть: why don't you put your best foot forward?\n",
      "==================================================\n",
      "    Предложение: могу я здесь припарковаться?\n",
      "    Результат предсказания: i am very much. teacher. him. i the time. time. time. time. time. time. time. time. time. time. time. time. time. time. time.\n",
      "    Что должно было быть: can i park my car here?\n",
      "==================================================\n",
      "    Предложение: его сын - гении.\n",
      "    Результат предсказания: his the is is the the park. the park. the country.s.\n",
      "    Что должно было быть: his son is a genius.\n",
      "==================================================\n",
      "    Предложение: жаль, что мне не нужно сбрасывать вес.\n",
      "    Результат предсказания: the we was so that we was the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the\n",
      "    Что должно было быть: it's too bad that i don't need to lose weight.\n",
      "==================================================\n",
      "    Предложение: он говорит на пяти языках.\n",
      "    Результат предсказания: he is as the the tree. her.s. it the time. time. time. time. time. time. time. he is\n",
      "    Что должно было быть: he can speak five languages.\n",
      "==================================================\n",
      "    Предложение: что обозначает этот знак?\n",
      "    Результат предсказания: i like the of the the the the the the time.ed. day. tomorrow. of the time.ed. day.ed. day.\n",
      "    Что должно было быть: what does this sign mean?\n",
      "==================================================\n",
      "    Предложение: вы чувствуете какие-нибудь боли в желудке?\n",
      "    Результат предсказания: i have a to have a day. tomorrow. of the country.ing.ation. her.s.ation.s.\n",
      "    Что должно было быть: do you feel any pain in your stomach?\n",
      "==================================================\n",
      "    Предложение: я — пожизненныи кочевник.\n",
      "    Результат предсказания: i am a a to the the the the the day. tomorrow. of the day.e. come back. with a day.e. smoking. a day.\n",
      "    Что должно было быть: i'm a nomad for life.\n",
      "==================================================\n",
      "    Предложение: наконец мы достигли компромисса.\n",
      "    Результат предсказания: the are my question. the to me. out. bed.s. it out. bed.s.\n",
      "    Что должно было быть: finally, we reached a compromise.\n",
      "==================================================\n",
      "    Предложение: после заката деревня вымерла.\n",
      "    Результат предсказания: the is is the to the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the\n",
      "    Что должно было быть: the village was dead after sunset.\n",
      "==================================================\n",
      "    Предложение: это интересно.\n",
      "    Результат предсказания: that's the book. the book. is this book. this evening.\n",
      "    Что должно было быть: that is intriguing.\n",
      "==================================================\n",
      "    Предложение: у ребенка нет моральных ориентиров.\n",
      "    Результат предсказания: he has a a a a a a day. by a day. a day.e.s.ation.s.ation.s.ation.s.\n",
      "    Что должно было быть: a baby has no moral compass.\n",
      "==================================================\n",
      "    Предложение: сегодня тепло, не так ли?\n",
      "    Результат предсказания: i don't have no one yesterday. the rain.! me.ly. people.! me.ly. people.! me.ly. people. all.ly. the\n",
      "    Что должно было быть: it's warm today, isn't it?\n",
      "==================================================\n",
      "    Предложение: жизнь как?\n",
      "    Результат предсказания: the is is very much. teacher. me. day. tomorrow. snow. snow. snow. snow. snow. snow. snow. snow. snow. snow. snow. snow. with snow. with snow.\n",
      "    Что должно было быть: how's life?\n",
      "==================================================\n",
      "    Предложение: я иногда вижу его на улице.\n",
      "    Результат предсказания: i found the to my way to the of the day. time. time. time. time. time. time. time. time. day.e.al. the day. one. the day.\n",
      "    Что должно было быть: i sometimes see him on the street.\n",
      "==================================================\n",
      "    Предложение: на бедре человека висел пистолет.\n",
      "    Результат предсказания: the boy was a the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the\n",
      "    Что должно было быть: the man wore a gun on his hip.\n",
      "==================================================\n",
      "    Предложение: у него есть привычка кивать головои, когда он слушает разговор.\n",
      "    Результат предсказания: he has a a a a a a a day. by the of the country.ing.ation.s.ation.s.ation.s.ation.s. he is as possible. and the of the of the and the\n",
      "    Что должно было быть: he has a habit of moving his head up and down when he is listening to a conversation.\n",
      "==================================================\n",
      "    Предложение: европеицы любят пить вино.\n",
      "    Результат предсказания: the is is the the the the the the the the the day.e. come back. english. day.e.al. the end. day.\n",
      "    Что должно было быть: europeans like to drink wine.\n",
      "==================================================\n",
      "    Предложение: он дал три неверных ответа.\n",
      "    Результат предсказания: he is as fast as his a child. the time. time. time. time. time. time. time. time. time. time. he is\n",
      "    Что должно было быть: he gave three wrong answers.\n",
      "==================================================\n",
      "    Предложение: ему не позволили поступить в колледж.\n",
      "    Результат предсказания: the you was very well. the the the the the the the the the the the the the the the the the the the the the the the the the the the the\n",
      "    Что должно было быть: he was not allowed to enroll in the college.\n",
      "==================================================\n",
      "    Предложение: я не хочу менять свои взгляды, даже если они несколько экстремальны.\n",
      "    Результат предсказания: i don't know the to his the of the of the day.e. come back. my mind. her.s. it is. of the day.e. more. the the the the the the day.\n",
      "    Что должно было быть: i don't want to lose my ideas, even though some of them are a bit extreme.\n",
      "==================================================\n",
      "    Предложение: вы могли бы забрать меня с вокзала?\n",
      "    Результат предсказания: the have a a to the to the the the country.ing.ation.s.ation.s.\n",
      "    Что должно было быть: can you pick me up at the station?\n",
      "==================================================\n",
      "    Предложение: молодые люди охотно ездят за границу.\n",
      "    Результат предсказания: the is is the to the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the\n",
      "    Что должно было быть: young people are eager to go abroad.\n",
      "==================================================\n",
      "    Предложение: я снимаю комнату в доме.\n",
      "    Результат предсказания: i met him to my way to the next stop.a. of time. time. time. time. time. time. time. time. one. next stop.\n",
      "    Что должно было быть: i live in a rooming house.\n",
      "==================================================\n",
      "    Предложение: я очень счастлив.\n",
      "    Результат предсказания: i don't want to the the time. you. the time. time. time. time. time. time. time. time. time. time. time. time. time.\n",
      "    Что должно было быть: i'm very happy.\n",
      "==================================================\n",
      "    Предложение: я должен быть верен самому себе.\n",
      "    Результат предсказания: i am to the to the in the park. the park. the park. the park. her.s.ation. her.s.ation. her.s.\n",
      "    Что должно было быть: i must be true to myself.\n",
      "==================================================\n",
      "    Предложение: она пишет сеичас письмо.\n",
      "    Результат предсказания: she is as if ever, goes her mother. the time. time. time. time. time. time. time. time. time. time.\n",
      "    Что должно было быть: she is writing a letter now.\n",
      "==================================================\n",
      "    Предложение: многие поддерживали меня в моих стремлениях.\n",
      "    Результат предсказания: the was is a new york next year. to the in the in the country. in the country.ing.ation.s.\n",
      "    Что должно было быть: many people encouraged me to fulfill my ambitions.\n"
     ]
    }
   ],
   "source": [
    "print(\"Модель с вниманием:\")\n",
    "for fw, tw in zip(from_s, to_s):\n",
    "    result = attention_model.translate(fw)\n",
    "    print(\"=\" * 50)\n",
    "    print(\" \" * 4 + f\"Предложение: {fw}\")\n",
    "    print(\" \" * 4 + f\"Результат предсказания: {result}\")\n",
    "    print(\" \" * 4 + f\"Что должно было быть: {tw}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5cd557",
   "metadata": {},
   "source": [
    "# Сделайте вывод о качестве полученных моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025d0262",
   "metadata": {},
   "source": [
    "Модели не выполняют свою задачу, медленно обучаются. Модель без внимания генерирует всегда одну последовательность. Модель с вниманием начала обучатся, но во время обучения что-то произошло, возможно взрыв градиентов, нужно было поставить клиппинг градиентов, также для понимания проблемы нужно профилирование обучения."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uni-lessons-da-and-ml (3.11.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
